{
    "Obelix": {
        "checkpoints": [
            {
                "steps": 349980,
                "file_path": "results\\Obelix-03\\Obelix\\Obelix-349980.nn",
                "reward": 4.802750064933207,
                "creation_time": 1602508075.8417022
            },
            {
                "steps": 399974,
                "file_path": "results\\Obelix-03\\Obelix\\Obelix-399974.nn",
                "reward": 3.6530000183265656,
                "creation_time": 1602508243.1663206
            },
            {
                "steps": 449995,
                "file_path": "results\\Obelix-03\\Obelix\\Obelix-449995.nn",
                "reward": 4.1561250551458215,
                "creation_time": 1602508410.1808856
            },
            {
                "steps": 499972,
                "file_path": "results\\Obelix-03\\Obelix\\Obelix-499972.nn",
                "reward": 5.575555637815139,
                "creation_time": 1602508577.1904533
            },
            {
                "steps": 500036,
                "file_path": "results\\Obelix-03\\Obelix\\Obelix-500036.nn",
                "reward": 5.575555637815139,
                "creation_time": 1602508580.9843392
            }
        ],
        "final_checkpoint": {
            "steps": 500036,
            "file_path": "results\\Obelix-03\\Obelix.nn",
            "reward": 5.575555637815139,
            "creation_time": 1602508580.9843392
        }
    },
    "metadata": {
        "stats_format_version": "0.1.0",
        "mlagents_version": "0.20.0",
        "tensorflow_version": "2.3.0"
    }
}